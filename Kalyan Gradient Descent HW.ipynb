{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why would you use batch gradient descent vs stochastic graidient descent? / When do you know to use a particular optimization algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch and gradient descent are two methods to attempt to find the global minimum of a model's cost function. \n",
    "\n",
    "Batch gradient descent chooses a random point from the entire cost function. It then 'decides' to move either left or right depending on the sign of the derivative of the function at that point. Once it moves(the step size is determined by the learning rate), it continues to do so until it meets a point where the derivative is close to zero. Like this, the algorithm determines when to stop going downhill and makes an estimate of where the global minimum is.\n",
    "\n",
    "This process can be slow because the entire training set(from which we get the base for our error function calculation) must be iterated through. This is especially the case when the dataset is too big to fit in main memory. Stochastic gradient descent corercts this problem by observing a subset of the original dataset. This method is computationally  cheap as well. However, one major drawback is that SGD can be prone to getting 'stuck' in local minima and not produce the true result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is dependency injection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dependency is just another object that your class needs to function. So if a model gets data on a database, the model is dependent on(or has a 'dependency on') the database.\n",
    "\n",
    "Dependency injection just means that we push the dependency back in to the class(our model) from the outside. The Cat Dog class example that we did in class is an example of this. \n",
    "\n",
    "This begs the question; why should we inject dependencies in the first place -- they seemed pretty pointless and cumbersome in the cat dog example. It decouples the class's construction from the construction of it's dependencies. Code should depend on abstractions: by depending on abstractions, we're decoupling our implementations from each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Compare the number of iterations it takes for each algorithm to obtain an estimate accurate to 1e-3 (you may wish to set a cap for maximum number of iterations). Which method converges to the optimal point in fewer iterations? Briefly explain why this result should be expected. \n",
    "\n",
    "## Compare the performance of stochastic gradient descent for the following learning rates: 1, 0.1, 0.001, 0.0001. Based on your observations, briefly describe the effect of the choice of learning rate on the performance of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, an SGD method would produce a much better rate(in terms if both processing cost and speed). It would be interesting to see the difference in 'rates' when modifiying the learning rate. I look forward to doing it in the future. In the meantime, I will google everything."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
